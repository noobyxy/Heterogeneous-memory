## tensor contraction

### 张量及张量收缩的理解

* 参考：[张量基础知识 - 百度文库 (baidu.com)](https://wenku.baidu.com/view/0f7691e7bdd126fff705cc1755270722182e59ef.html)

* 张量：矩阵概念的推广。向量为一维张量，矩阵为二维张量。

* 张量的mode：即张量的形状

  >二维张量 $\begin{bmatrix}1 \;2\;3\\3 \;4\;6\end{bmatrix}$的mode为2*3

* 张量的乘法：类似笛卡尔积。n维张量和m维张量的乘积是n+m维张量

  >张量 $\begin{bmatrix}1  \;2\\3 \;4\end{bmatrix}$ 和张量 $[5 \;6]$ 的乘积为三维张量：
  >$$
  >\begin{bmatrix}
  >\begin{bmatrix}
  >5\;10\\
  >15\;20
  >\end{bmatrix}\begin{bmatrix}
  >6\;12\\
  >18\;24
  >\end{bmatrix}
  >\end{bmatrix}
  >$$
  
* 张量收缩：向量内积、矩阵乘法在张量上的推广

  >矩阵乘法：2维张量 $A_{ij}$ 乘上2维得到2维张量 $B_{kl}$ 得到二维张量，且要求 $j=k$
  >
  >m 维张量 $A_{abc}$ 和 n 维张量 $B_{cdef}$ 的收缩结果为 $C_{abdef}$ ，m+n-2 维，缩并的维数 c 相等！
  >
  >个人理解：张量乘法和张量收缩的关系有点像数据库中的乘积和自然连接
  
* 稀疏张量的表示：将非零的位提取出来，用各分量的取值进行表示（类似稀疏矩阵的表示！）。

- 稀疏张量乘法（SpGEMM）  稀疏张量收缩（SpTC）  本文的算法：Sparta



### 提出背景及算法适用

稀疏张量的张量收缩运算在量子物理、量子化学、深度学习领域都有广泛的应用。（**展示的重点**）

本文提出了一种高效的Sparta算法用于进行稀疏张量的收缩运算。

* 张量收缩运算有三个难点
  1. 输出张量的模式（输出的大小&non-zero pattern）未知。张量的其他运算，例如张量乘法运算能够预测出输出张量的大小和0分布，但张量收索运算不行，给内存的分配带来了挑战。
  2. 不规则的内存访问：需要对各个分量的不同下标进行寻址，开销较大。（对相乘的第二个向量的访问不规则，对cache不友好）
  3. 巨大的张量维数引起大量的内存消耗，对传统的DRAM架构造成很大的考验（较大的输入、输出和中间结果需要存放）。
* 解决方案
  * 针对前两个问题提供了Sparta算法
  * 针对第三个问题适用了 **PMM-based HM** 架构（PMM: Persistent Memory Module, HM: heterogeneous memory）。



### 算法理解

算法思想：在缩并运算 $A*B$ 中，对张量 $B$ 的部分信息使用哈希表进行缓存，避免之后对张量 $B$ 的大量随机访问。

TO BE FINISH......

 